{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b2acae-1fb6-4a6f-911f-5bc2fc492cac",
   "metadata": {
    "id": "Aunr_fxE2ABj"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5213dc4d-2e9e-4ba1-b325-883a67fb2b9f",
   "metadata": {
    "id": "Cpnj3zsDunPv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# PyTorch coding expects data to be put in specific objects\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# here we just get some real data and preprocessing\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fe43a-f056-4cfc-86c1-804dd89454a9",
   "metadata": {
    "id": "y6EUDXKQ2GnM"
   },
   "source": [
    "### Example of a Neural Net in PyTorch for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eabce01-3c8f-46d1-bb81-bad61420f4e9",
   "metadata": {
    "id": "ngkIKLOzWzhm"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabb21d8-bc22-4790-ab9f-b35e7f380bc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTQicKbgW0cm",
    "outputId": "e008995a-7ef3-4d63-c4dc-69a7deadc980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d474ad-cce2-4489-94a7-31cdf4a00c0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jTEr9KCXQ3t",
    "outputId": "0adb8ca1-ada2-44ab-bbf8-06619a3039cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3cb24b-4970-4a8c-9802-831d6944ffe2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5BjXLsqbCVP",
    "outputId": "86ed503a-c08e-4812-e1e1-5c9797fe7f6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac90391-bcac-4ea6-9f40-f448b67e1294",
   "metadata": {},
   "source": [
    "The hidden layer needs 14*5 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d413f2d-91d4-41ac-8352-48a99f7acb36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5N9m-fsmSYD",
    "outputId": "2597ae1a-7fd5-4a32-bfea-0174025f4dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0032\n",
      "Epoch [20/100], Loss: 0.0003\n",
      "Epoch [30/100], Loss: 0.0001\n",
      "Epoch [40/100], Loss: 0.0001\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [60/100], Loss: 0.0000\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0001\n",
      "Epoch [100/100], Loss: 0.0000\n",
      "Accuracy on test set: 0.9259\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "# Standardize the features\n",
    "scale = StandardScaler()\n",
    "\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(scale.fit_transform(X_train), dtype=torch.float64)\n",
    "X_test_tensor = torch.tensor(scale.transform(X_test), dtype=torch.float64)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "# Define a simple neural network\n",
    "class WineNet(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(WineNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 16).double()\n",
    "        self.a1 = nn.PReLU().double()  # Define PReLU as a class member\n",
    "        self.hl2 = nn.Linear(16,8).double()\n",
    "        self.a2 = nn.GELU().double()\n",
    "        self.fc2 = nn.Linear(8, 3).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a1(self.fc1(x))  # Apply PReLU activation\n",
    "        x = self.a2(self.hl2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = WineNet(X_train.shape[1])\n",
    "# this criterion is based on the type of problem you are solving\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# here we use a flavor of gradient descent to update the weights of the model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # a peculiar aspect of Pytorch -> you put the model in a \"training\" state\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # this resets the optimizer before each calculation of the direction for updating the weights\n",
    "        optimizer.zero_grad()\n",
    "        # do a forward propagation\n",
    "        outputs = model(X_batch)\n",
    "        # use the criterion to compute the loss of the batch\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        # here we backpropagate to update the weigths\n",
    "        loss.backward()\n",
    "        # here, the next line is actually updating the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        y_pred_list.append(y_pred)\n",
    "        y_true_list.append(y_batch)\n",
    "\n",
    "    y_pred = torch.cat(y_pred_list)\n",
    "    y_true = torch.cat(y_true_list)\n",
    "    accuracy = accuracy_score(y_true.numpy(), y_pred.numpy())\n",
    "    print(f'Accuracy on test set: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0915ac1-68dd-4c69-bbad-0c1b25b7bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "WineNet                                  --\n",
       "├─Linear: 1-1                            70\n",
       "├─PReLU: 1-2                             1\n",
       "├─Linear: 1-3                            18\n",
       "=================================================================\n",
       "Total params: 89\n",
       "Trainable params: 89\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc563a7b-4b14-44f4-9e84-58157f8077ea",
   "metadata": {
    "id": "abSQUWCW4zsi"
   },
   "source": [
    "### Example of Classification w/ Class Imbalance\n",
    "\n",
    "Reference: https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/04.first-neural-network.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4a4d16-22cc-419c-bf1f-acfc34be06ac",
   "metadata": {
    "id": "JLojkU_2GXsC"
   },
   "source": [
    "### Example of a Neural Net in PyTorch for Regression Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac5719dd-393f-4f15-b0b6-744530150253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://github.com/dvasiliu/AML/blob/main/Data%20Sets/concrete.csv?raw=true')\n",
    "y = data['strength'].values\n",
    "x = data.drop(columns=['strength']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c158a5b-e489-447f-860e-60fa06222df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "522f294f-d696-4660-b1df-fd8a122021f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgZpQUz0GVTZ",
    "outputId": "c80f1819-bba7-479d-ebc2-aba0e4e7a81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 30.1968\n",
      "Epoch [20/100], Loss: 36.9732\n",
      "Epoch [30/100], Loss: 21.5745\n",
      "Epoch [40/100], Loss: 29.1898\n",
      "Epoch [50/100], Loss: 16.2504\n",
      "Epoch [60/100], Loss: 23.6800\n",
      "Epoch [70/100], Loss: 27.8644\n",
      "Epoch [80/100], Loss: 70.0342\n",
      "Epoch [90/100], Loss: 8.8895\n",
      "Epoch [100/100], Loss: 11.6931\n",
      "Test Loss: 35.7237\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic regression data\n",
    "#X, y = make_regression(n_samples=1000, n_features=12, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=301)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float64)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float64)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float64).view(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float64).view(-1, 1)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "# Define a simple neural network for regression\n",
    "class RegressorNN(nn.Module):\n",
    "    def __init__(self,n_features):\n",
    "        super(RegressorNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_features, 16).double()\n",
    "        self.a1 = nn.PReLU().double()\n",
    "        self.layer2 = nn.Linear(16, 8).double()\n",
    "        self.a2 = nn.PReLU().double()\n",
    "        self.layer3 = nn.Linear(8, 1).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.a1(self.layer1(x))\n",
    "        x = self.a2(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define loss function and optimizer\n",
    "model = RegressorNN(x.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the model\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # this resets the optimizer before each calculation of the direction for updating the weights\n",
    "        optimizer.zero_grad()\n",
    "        # do a forward propagation\n",
    "        outputs = model(X_batch)\n",
    "        # use the criterion to compute the loss of the batch\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        # here we backpropagate to update the weigths\n",
    "        loss.backward()\n",
    "        # here, the next line is actually updating the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluating the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Sample prediction\n",
    "# sample_data = torch.tensor(scaler.transform(np.array([[1.2, 2.3, 3.4, 4.5, 5.6, 6.7, 7.8, 8.9, 9.0, 0.1,0.4,0.8]])), dtype=torch.float32)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     sample_prediction = model(sample_data)\n",
    "#     print(f'Sample Prediction: {sample_prediction.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b297605-d61d-49a7-8886-048248d4afdb",
   "metadata": {
    "id": "DXlOgFMM2jWN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
