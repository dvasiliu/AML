{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47zhKygt16DR"
   },
   "source": [
    "##<font color='navy' face='Helvetica' size=12pt>Introduction to Natural Language Processing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18780,
     "status": "ok",
     "timestamp": 1701718037579,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "ZR2Je4GwTD43",
    "outputId": "773c0b8c-61f5-4a45-eaaa-aec37930ef9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeSccFn3kPfE"
   },
   "source": [
    "<font color='crimson'>**Objective:** use speech and words along with computer run algorithms.\n",
    "\n",
    "<span style=\"font-family:Calibri; color:darkblue; font-size:18pt;\">Examples of projects/research with NLP:</span>\n",
    "\n",
    "<font color='blue'>*Sentiment Analysis*</font> - How positive or negative is text about a topic?\n",
    "\n",
    "<font color='blue'>*Prediction*</font> - What genres should Netflix classify a movie as to maximize views? Based on product reviews, can we predict the star rating of a product?\n",
    "\n",
    "<font color='blue'>*Translation*</font> - Recognize words in one language to provide similar words in another.\n",
    "\n",
    "**Playground:** https://www.deepl.com/translator\n",
    "\n",
    "\n",
    "<font color='blue'>*Summarization*</font> - Take a long document and produce a shorter one (a synthesis) without losing meaningful information.\n",
    "\n",
    "\n",
    "<font color='forestgreen'>**Methods:**</font> <span style=\"font-family:Calibri; color:red; font-size:12pt;\">The main idea is to quantify the occurrence of relevant words and, based on the context, to map them into vectors. That is to say that we want to create mathematically representable quantities from words and text; they will serve as features for data analysis. One approach is separate the text data into sentences and then sentences can be used to extract (key) words and expressions.</span>\n",
    "\n",
    "###**Regular Expressions (regex)**\n",
    "\n",
    "Goal: provide a language that allows us to search for different text strings.\n",
    "\n",
    "For example, Regular Expressions (frequently called “regex”) allows us to label all tweets with a “1” if they contain the following list of words:\n",
    "\n",
    "- college\n",
    "- College of\n",
    "- colleges\n",
    "- The College\n",
    "\n",
    "The idea is to detect that in all expressions above we have the same concept \"college\".\n",
    "\n",
    "\n",
    "\n",
    "<font color='blue' face='Calibri' size=5pt>Examples of common REGEX patterns</font>\n",
    "\n",
    "**[tT]**imber  - would match lower or uppercase T\n",
    "\n",
    "**[A-Z]** - would match any capital character\n",
    "\n",
    "**[a-z]** - would match any lowercase character\n",
    "\n",
    "**[0-9]** - would match any single number (i.e., 9)\n",
    "\n",
    "**[^A-Z]** - would match anything that isn’t an uppercase letter.\n",
    "\n",
    "**\\w** - would match any letter.\n",
    "\n",
    "A comprehensive manual on regex can be found here:\n",
    "https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjXxyULYjYT9"
   },
   "outputs": [],
   "source": [
    "# import regex in Python\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XnTsc2O60Ol",
    "outputId": "89f108a3-1ee0-4f2b-c07a-ff606613758d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a match!\n"
     ]
    }
   ],
   "source": [
    "pattern = \"[cC]hoco\"\n",
    "pattern2 = \"[cC]ustard\"\n",
    "pattern3 = \"cake\"\n",
    "sentence1 = \"Chocolate is very delicious.\"\n",
    "sentence2 = \"This new recipe deliciously implemented a new idea about the texture of the chocolate.\"\n",
    "sentence3 = \"Chocolate has too many calories and we have to be careful.\"\n",
    "if re.search(pattern3, sentence1):\n",
    "  print(\"Match!\")\n",
    "else: print(\"Not a match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "c7uzyAEoroFB",
    "outputId": "8a546b35-e541-48c5-ea1f-863169d513a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[cC]hoco'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BaUHIou70ez"
   },
   "source": [
    "###An example for replacing the spaces between words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "EKtrHwsD65vM",
    "outputId": "2b055dd2-1c55-46fb-f2ab-adb4df5838a0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This*chocolate*is*delicious*but*it*may*have*too*many*calories**such*as*400*'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This chocolate is delicious but it may have too many calories, such as 400.\"\n",
    "re.sub('[^a-zA-Z0-9]','*',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnJyZUQ5D_Uj"
   },
   "outputs": [],
   "source": [
    "text = \"This chocolate is delicious but it may have too many calories, such as five hundred.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8alHKVvSKAZ",
    "outputId": "3a12dc8b-2b48-4b1a-98d6-38047b35b4dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'chocolate',\n",
       " 'is',\n",
       " 'delicious',\n",
       " 'but',\n",
       " 'it',\n",
       " 'may',\n",
       " 'have',\n",
       " 'too',\n",
       " 'many',\n",
       " 'calories,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'five',\n",
       " 'hundred.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYZnVLP7D_bo"
   },
   "outputs": [],
   "source": [
    "info = text.split(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J3FhdSloEXyl",
    "outputId": "aa1c0b5f-c418-44cf-e1ba-7d4ec77dacec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info is now an array of different words\n",
    "info[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dk4zqK08L7y"
   },
   "source": [
    "###An example for matching a patttern (a sequence of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL91n3Zy7x08",
    "outputId": "3d534673-0772-4799-851e-7f046c9405d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[cC]hoco\"\n",
    "sequence = \"Chocolate is delicious\"\n",
    "if re.match(pattern, sequence):\n",
    "  print(\"Match!\")\n",
    "else: print(\"Not a match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxp0kAGuMc2y"
   },
   "source": [
    "### Rooting words is very important ! (in short, an identifier of the meaning of the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAp3N5p88Wwc",
    "outputId": "16feeed9-835d-4f08-d621-efc73115b9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"good for you\"\n",
    "sentence = \"Chocolate is delicious and good for you\"\n",
    "if re.search(pattern, sentence):\n",
    "  print(\"Match!\")\n",
    "else: print(\"Not a match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeXHM2fn9zil"
   },
   "source": [
    "###Example:\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1AMHbSgq3MHcv8Q8ljnHvl5IkxTKkzGkx'\n",
    "width='600px' />\n",
    "<figcaption>Data from Twitter</figcaption></center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fr1AOY-18eRD"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Rep. Stephanie Murphy Verified account @RepStephMurphy Aug 30 More Celebrating 100yrs of coeducation at @williamandmary,\n",
    "        it was a true honor to return to my alma mater & join its first female president, Katherine Rowe, to welcome students at their convocation.\n",
    "        I spoke about the power of patriotism & the urgent need for active, engaged citizens.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51YBSini_hUb",
    "outputId": "9054e5a6-9c79-4314-dea9-a16dd96cb0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[cC]elebrat\"\n",
    "if re.search(pattern, text):\n",
    "  print(\"Match!\")\n",
    "else: print(\"Not a match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfxPZBsd_mXj",
    "outputId": "f3014188-5867-4763-c4de-8f3d8a6d56ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\welebrat[a-z]+\"\n",
    "if re.search(pattern, text):\n",
    "  print(\"Match!\")\n",
    "else: print(\"Not a match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WE1A7C8AeVy"
   },
   "source": [
    "<font face='Calibri' color='blue' size=5pt>The Bag of Words model (BoW)</font>\n",
    "\n",
    "**Main Goal:** use concurrences within context and counts of keywords to make predictions.\n",
    "\n",
    "**Observation:** there are many words that do not matter (such as prepositions or definite and indefinite articles).\n",
    "\n",
    "**Important:** each word can be translated into a binary value of occurrence.\n",
    "\n",
    "<span style=\"font-family:Calibri; color:darkblue; font-size:5pt;\">Analog Example:</span>\n",
    "\n",
    "*Statement 1*: Jurassic World was the pinnacle of human achievement.\n",
    "\n",
    "*Statement 2*: Human kind would be better without Jurassic World.\n",
    "\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1EUGNgop58BOOhFGHR3iKs5gXbrji6jEM'\n",
    "width='600px' />\n",
    "<figcaption>What is the difference in the statements above?</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "**Method**: we discard the *stopwords* such as articles, prepositions, verbs and retain the *corpus* (important words or *roots* of important words).\n",
    "\n",
    "\n",
    "\n",
    "A simple model based on this data:\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://drive.google.com/uc?id=1-uuXfXiYlmub8DauhxhYYCP2TKqfdvoB'\n",
    "width='600px' />\n",
    "<figcaption>The differences can be highlighted by using a count/vectorizer method</figcaption></center>\n",
    "</figure>\n",
    "\n",
    "**Main idea:** analyze differences and co-occurrencies.\n",
    "\n",
    "**Known Problems:**\n",
    "\n",
    " - If some sentences are much longer in length, the vocabulary would increase and as such, the length of the vectors would increase; this is a dimensionality problem.\n",
    " - The new sentences may contain more different words from the previous sentences.\n",
    " - The vectors would also contain many zeros, thereby resulting in a sparse matrix.\n",
    " - No information on the grammatical structure or the actual ordering of the words is being used.\n",
    "\n",
    "**Possible Solution:** Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "The term frequency-inverse document frequency is a measure that quantifies the importance of a word in the context of a document or a *corpus*.\n",
    "\n",
    "The *term-frequency* of a word is the relative frequency of the term in the context of the document.\n",
    "\n",
    "$$\\text{TF}(t,d):=\\frac{\\text{# of times the term appears in the document}}{\\text{# of terms in the document }}$$\n",
    "\n",
    "\n",
    "The *inverse document frequency* is defined as:\n",
    "\n",
    "$$\\text{IDF}(t,d):=\\log\\left(\\frac{\\text{# of documents}}{\\text{# of documents with term } t}\\right)$$\n",
    "\n",
    "Our quantification of relative importance is defined as the product between TF and IDF.\n",
    "\n",
    "TF-IDF gives larger values for less frequent words and is high when both IDF and TF values are high, for instance the word is rare in all the documents combined but frequent in a single document.\n",
    "\n",
    "A good Python example can be found here:\n",
    "\n",
    "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1966,
     "status": "ok",
     "timestamp": 1701717957507,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "t-rVM7uOAFj8",
    "outputId": "255cc1b6-8a71-4530-ec94-5fb0a5716d1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcgT03h3BW-t"
   },
   "outputs": [],
   "source": [
    "text = open(\"drive/MyDrive/Data Sets/Christmas_Carol.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmmUvIi4YTSy",
    "outputId": "c1d2b9aa-254d-4b49-b989-95f6f72e2de4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158414"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwPgD4RsBeVS"
   },
   "source": [
    "<font face=\"Calibri\" color='navy' size=4pt>We can extract all the sentences (based on punctuation):</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PobVsJyzB9mJ"
   },
   "outputs": [],
   "source": [
    "dataset = nltk.sent_tokenize(text)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower()\n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i])\n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "InfAZVegJWFY",
    "outputId": "fa255177-e8cc-4062-d800-5619327f8f36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'mrs cratchit made the gravy ready beforehand in a little saucepan hissing hot master peter mashed the potatoes with incredible vigour miss belinda sweetened up the apple sauce martha dusted the hot plates bob took tiny tim beside him in a tiny corner at the table the two young cratchits set chairs for everybody not forgetting themselves and mounting guard upon their posts crammed spoons into their mouths lest they should shriek for goose before their turn came to be helped '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "iIAkuuEdCEZ5",
    "outputId": "e5077fa4-5dd6-4f5f-f61e-a6ddba877a91"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'they could only have come from the old man at my side and yet he sat now as absorbed as ever very thin very wrinkled bent with age an opium pipe dangling down from between his knees as though it had dropped in sheer lassitude from his fingers '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the 2001th sentence\n",
    "dataset[2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VbuMt_-3gNt"
   },
   "source": [
    "What do you notice? There are no capital letters, no punctuation (because the computer does not need them).\n",
    "\n",
    "We can also determine how frequent are the different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Liv9PCWGCOp7"
   },
   "outputs": [],
   "source": [
    "# we can count the occurrencies of different words\n",
    "# Creating the Bag of Words model\n",
    "word2count = {} # this is a list\n",
    "for data in dataset:\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for word in words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdglAkPpCZp8",
    "outputId": "8ec8abf7-c9e8-4a5a-f374-af9f02f219f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count.get('ghost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7AscS7Z2FnJ"
   },
   "outputs": [],
   "source": [
    "word2count.get('dinosaur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpgPnOqmDOzp"
   },
   "source": [
    "This means that the word \"ghost\" appeared 95 time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icqKTzLnCaZl",
    "outputId": "a3ed125d-6914-4cfd-9d41-970374161a6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2count.get('the') # however 'the' is a stopword so it should be counted!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a81WOQYhDQn5"
   },
   "source": [
    "<font face=\"Calibri\" color='navy' size=4pt>We can determine what are the most frequent words, for example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wT3CP1V4DhxL"
   },
   "outputs": [],
   "source": [
    "# the top 100 most frequent words\n",
    "import heapq\n",
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldxUtPD_EIZs"
   },
   "source": [
    "Indeed this is a story about \"Christmas\" and \"love\"...\n",
    "\n",
    "Important: we want to discard all the unimportant words (as known as \"stopwords\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1701718093082,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "LnDYV22LEAKG",
    "outputId": "c3a84275-9d84-4671-aaec-07dda3dc0ee8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Stopword dictionary\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "# For stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "3cv4uf8jEmfY",
    "outputId": "dcadf609-0ef6-4c01-f476-f67a5a0848a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'mr cratchit made gravi readi beforehand littl saucepan hiss hot master peter mash potato incred vigour miss belinda sweeten appl sauc martha dust hot plate bob took tini tim besid tini corner tabl two young cratchit set chair everybodi forget mount guard upon post cram spoon mouth lest shriek goos turn came help'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = re.sub('[^a-zA-Z0-9 ]','',dataset[999])\n",
    "# Make everything lower case\n",
    "txt = txt.lower()\n",
    "# Make it a list of words\n",
    "txt = txt.split()\n",
    "# Get all the stop words out\n",
    "txt = [word for word in txt if not word in set(stopwords.words('english'))]\n",
    "# Stem the words\n",
    "txt = [stemmer.stem(word) for word in txt]\n",
    "# Put it all back together and look at the result\n",
    "' '.join(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cShN8rfsEyL5"
   },
   "source": [
    "..and we want to do this for every sentence in the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZkkVIhVExLH"
   },
   "outputs": [],
   "source": [
    "corpus = [] # the name 'corpus' refers to the sentences after we throwed all stopwords and we rooted the remaining ones\n",
    "for i in range(len(dataset)):\n",
    "    txt = re.sub('[^a-zA-Z0-9 ]','',dataset[i])\n",
    "    txt = txt.lower()\n",
    "    txt = txt.split()\n",
    "    txt = [word for word in txt if not word in set(stopwords.words('english'))]\n",
    "    txt = [stemmer.stem(word) for word in txt]\n",
    "    txt = ' '.join(txt)\n",
    "    corpus.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9n2VU3JwE4DL"
   },
   "outputs": [],
   "source": [
    "corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGZOJeHKFA7r"
   },
   "outputs": [],
   "source": [
    "# we can count the occurrencies of different words in the corpus\n",
    "# Creating the Bag of Words model\n",
    "word2count = {}\n",
    "for data in corpus:\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for word in words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbheF3ELFGyq",
    "outputId": "f8f71bb0-5eff-41d5-b247-d6d6e6aa761a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'upon',\n",
       " 'holm',\n",
       " 'one',\n",
       " 'would',\n",
       " 'mr',\n",
       " 'man',\n",
       " 'could',\n",
       " 'littl',\n",
       " 'see',\n",
       " 'may',\n",
       " 'come',\n",
       " 'hand',\n",
       " 'well',\n",
       " 'room',\n",
       " 'know',\n",
       " 'look',\n",
       " 'think',\n",
       " 'us',\n",
       " 'must',\n",
       " 'shall',\n",
       " 'time',\n",
       " 'day',\n",
       " 'door',\n",
       " 'two',\n",
       " 'came',\n",
       " 'good',\n",
       " 'matter',\n",
       " 'face',\n",
       " 'back',\n",
       " 'case',\n",
       " 'work',\n",
       " 'hous',\n",
       " 'go',\n",
       " 'way',\n",
       " 'ask',\n",
       " 'might',\n",
       " 'ye',\n",
       " 'like',\n",
       " 'night',\n",
       " 'much',\n",
       " 'say',\n",
       " 'found',\n",
       " 'seem',\n",
       " 'heard',\n",
       " 'eye',\n",
       " 'open',\n",
       " 'even',\n",
       " 'away',\n",
       " 'made',\n",
       " 'miss',\n",
       " 'never',\n",
       " 'howev',\n",
       " 'quit',\n",
       " 'noth',\n",
       " 'remark',\n",
       " 'tell',\n",
       " 'head',\n",
       " 'right',\n",
       " 'take',\n",
       " 'make',\n",
       " 'morn',\n",
       " 'sherlock',\n",
       " 'use',\n",
       " 'turn',\n",
       " 'gutenberg',\n",
       " 'cri',\n",
       " 'window',\n",
       " 'last',\n",
       " 'street',\n",
       " 'year',\n",
       " 'find',\n",
       " 'friend',\n",
       " 'left',\n",
       " 'side',\n",
       " 'project',\n",
       " 'paper',\n",
       " 'oh',\n",
       " 'saw',\n",
       " 'long',\n",
       " 'ladi',\n",
       " 'yet',\n",
       " 'thought',\n",
       " 'word',\n",
       " 'took',\n",
       " 'first',\n",
       " 'point',\n",
       " 'round',\n",
       " 'father',\n",
       " 'place',\n",
       " 'still',\n",
       " 'light',\n",
       " 'st',\n",
       " 'everi',\n",
       " 'watson',\n",
       " 'without',\n",
       " 'small',\n",
       " 'busi',\n",
       " 'young',\n",
       " 'put']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. and get the top 10 most frequent in the corpus:\n",
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-NGVIDzFL4J"
   },
   "source": [
    "## Application to Amazon customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1701718009739,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "qeNYrf-JcNp_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2522,
     "status": "ok",
     "timestamp": 1701718043583,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "soXF4QCQFOtz"
   },
   "outputs": [],
   "source": [
    "# this data is available via Kaggle\n",
    "df = pd.read_csv('drive/MyDrive/Data Sets/amazon_reviews.csv', quoting=2 )\n",
    "# Extract the ratings and text reviews\n",
    "data = df[['reviews.text', 'reviews.rating']].dropna().reset_index(drop=True)\n",
    "\n",
    "reviews = data['reviews.text']\n",
    "y = data['reviews.rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "n92B5NCDcSRI",
    "outputId": "1f896450-9527-4952-bdd6-28ad559f20a7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I've had this a week now. I also have a Kindle Fire HD I have had for about a year, with the case on, the Fire HD is heavy. I love the HD, and never leave home with out it, but many times I wish I could just slip my books in my pocket and run. I go a lot of places on the run, take others places where I wait for them to shop or what ever, and there is not WiFi to play on my Fire HD. I just want to read. My reading time has come up from one book a year to 50 books a year, and now my reading will go up even more.This was the perfect answer. So feather light It is incredible. It is taking me a bit to not swipe the screen to turn a page, and get used to the lay out and use of the various buttons, but after an hour I had read the built in owners manual, learned the ins and outs of the buttons and had it set up. It connected to my WiFi instantly. The on screen key board has taken a bit to get used to but once you use it a few times you can do it pretty fast.I wondered how all my content, library of books would be transferred from my Fire HD, to this device. To my pleasant surprise after connecting to my Wi-Fi, the next time I looked at the home menu my entire library of over 300 books was there, archived. I just click a title and it down loads in seconds.I honestly can't tell the difference between the print on this and the print on my Fire HD. Pixel wise, my eyes can't differentiate a thing.I love the texture look of a page from a book look. The no glare is amazing. There are times and places I can't read or see the screen on my Fire HD, and this just runs circles around the reading in bright light. Yes!Read more\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[289,'reviews.text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WeIav12x5CbA",
    "outputId": "434998cd-da1b-42a0-ffa8-9ab5c9f69756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[289]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDhklObNFb-V"
   },
   "source": [
    "To learn more about the data:   \n",
    "\n",
    "https://www.kaggle.com/bittlingmayer/amazonreviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPyC_Hub1k86"
   },
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "error",
     "timestamp": 1701718072214,
     "user": {
      "displayName": "Daniel Vasiliu",
      "userId": "13280890113502714012"
     },
     "user_tz": 300
    },
    "id": "1_7DersbFcfR",
    "outputId": "7d3ad422-8fb2-44d9-aff8-2b176b472920"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fa1f06f93263>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we make all letters lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extracting the different words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# we throw all the non-important words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# we make unique identifiers to words that have common roots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we assemble back the remaing rooted words into a pre-processed review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa1f06f93263>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we make all letters lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extracting the different words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# we throw all the non-important words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# we make unique identifiers to words that have common roots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we assemble back the remaing rooted words into a pre-processed review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "allreviews = []\n",
    "for i in range(len(reviews)):\n",
    "    txt = re.sub('[^a-zA-Z0-9 ]','',reviews[i]) # removes all special characters and punctuation\n",
    "    txt = txt.lower() # we make all letters lower case\n",
    "    txt = txt.split() # extracting the different words\n",
    "    txt = [word for word in txt if not word in set(stopwords.words('english'))] # we throw all the non-important words\n",
    "    txt = [stemmer.stem(word) for word in txt] # we make unique identifiers to words that have common roots\n",
    "    txt = ' '.join(txt) # we assemble back the remaing rooted words into a pre-processed review\n",
    "    allreviews.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cRgcjbYWIRRP",
    "outputId": "d9179dec-b23b-4cb9-ddcd-64888b5dd974"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'first rate high qualiti'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allreviews[257] # this btw is a 5 star review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWb4ZixhFpQ1"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_raw = cv.fit_transform(allreviews)\n",
    "X = X_raw.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwRkyYxBepBE"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "prep1 = TfidfVectorizer()\n",
    "X_raw = prep1.fit_transform(allreviews)\n",
    "X = X_raw.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUByyjezXNxZ",
    "outputId": "bbfd8ce8-fcc4-4e79-f510-92c619e7f56f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177, 5084)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Apv7dVGmfDy5",
    "outputId": "0f0c6a8c-51d8-44f5-f984-23cc2e3692c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu0wfsfugkdS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXibZEqWdPPU",
    "outputId": "6092cad3-6d49-43cd-8e80-f172eed5f3f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177, 5084)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukfkEpSMFuie"
   },
   "outputs": [],
   "source": [
    "# for the number of stars we say 5 star is a hit and less than 5 is a miss\n",
    "yb = y.where(y==5, other=0).where(y<5, other=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WD3-Corc6O1E",
    "outputId": "630bbe08-3380-4a4e-8d54-9a28ad84d6f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aig3TTew6SKJ",
    "outputId": "9392b65f-6044-4022-f726-19c3ea322bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqSbY30WIx1G",
    "outputId": "ee1059b6-c049-4dec-b372-1401cec139d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "1172    0.0\n",
       "1173    0.0\n",
       "1174    0.0\n",
       "1175    0.0\n",
       "1176    0.0\n",
       "Name: reviews.rating, Length: 1177, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_Do_3AbH9IG"
   },
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "LSBtBGAbF9Uj",
    "outputId": "c2e8297d-69e3-4d53-9df7-9caf12032f0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e378c888-3a20-4674-979b-80ac701374e9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not 5</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not 5</th>\n",
       "      <td>33</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e378c888-3a20-4674-979b-80ac701374e9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e378c888-3a20-4674-979b-80ac701374e9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e378c888-3a20-4674-979b-80ac701374e9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Not 5    5\n",
       "Not 5     33   83\n",
       "5         10  169"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = tts(X,yb,random_state=310,test_size=0.25)\n",
    "cls = LogisticRegression(random_state=310, solver='lbfgs')\n",
    "cls.fit(Xtrain,ytrain)\n",
    "ypred = cls.predict(Xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIO4S8lWJjdk",
    "outputId": "cd7907a2-c02f-4500-8dc4-3a6695c92955"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7050847457627119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1z-wgGbY6wVR",
    "outputId": "eded576a-4597-430c-a1c8-74be076ac03d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input features are based on the Bag of Words Model\n",
    "# the input features matrix X is sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOFJYAd-mNP_"
   },
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alkt9kTzmFqK"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yiHGREFmRQy"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5,weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Pnm2EprTmRWF",
    "outputId": "2184a2cf-23a0-448b-9e62-44a8f562dccd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not 5</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not 5</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Not 5    5\n",
       "Not 5     43   73\n",
       "5         21  158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,ytrain)\n",
    "ypred = model.predict(Xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNNCmCZwH_ky"
   },
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "fR17RiZMHkHa",
    "outputId": "83de23c0-35f7-4810-cb03-92bb25af50f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not 5</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not 5</th>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Not 5    5\n",
       "Not 5     82   34\n",
       "5         71  108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "cls = GaussianNB()\n",
    "cls.fit(Xtrain,ytrain)\n",
    "ypred = cls.predict(Xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vy4_0A11eZ6s",
    "outputId": "09a4f843-b82e-49aa-981a-9755802ca3cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440677966101694"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pea2T1NnIEC7"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "x9dpA18ZF6HZ",
    "outputId": "f4c4cd9d-b6bf-4fdb-e805-ef6ba254c6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not 5</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not 5</th>\n",
       "      <td>47</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Not 5    5\n",
       "Not 5     47   69\n",
       "5         12  167"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "cls = RandomForestClassifier(random_state=310, max_depth=100, n_estimators = 100)\n",
    "cls.fit(Xtrain,ytrain)\n",
    "ypred = cls.predict(Xtest)\n",
    "cm = confusion_matrix(ytest, ypred)\n",
    "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Va1QXBwpetaT",
    "outputId": "e29d4c17-0020-49b1-a452-66e7545654bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7254237288135593"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jGLmCiMI_sg"
   },
   "source": [
    "## Application to wine ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUtoy0hQI_Io"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GckK-WM1JlgQ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "wine_data = pd.read_csv('winemagdata130kv2.csv',quoting=2)\n",
    "wines = wine_data[[\"description\",\"points\"]]\n",
    "wines_subset = wines.sample(1000,random_state=1693).reset_index(drop=True)\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,len(wines_subset)):\n",
    "    wine_descriptions = re.sub('[^a-zA-Z0-9 ]','',wines_subset[\"description\"][i])\n",
    "    wine_descriptions=wine_descriptions.lower()\n",
    "    wine_descriptions = wine_descriptions.split()\n",
    "    wine_descriptions = [word for word in wine_descriptions if not word in set(stopwords.words('english'))]\n",
    "    stemmer = PorterStemmer()\n",
    "    wine_descriptions = [stemmer.stem(word) for word in wine_descriptions]\n",
    "    wine_descriptions = \" \".join(wine_descriptions)\n",
    "    corpus.append(wine_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSlRbCJpJ2uO"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "countVec = CountVectorizer()\n",
    "X_raw = countVec.fit_transform(corpus)\n",
    "X = X_raw.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-0xqoC4J_X0"
   },
   "outputs": [],
   "source": [
    "#### Visualize the distribution of the wine ratings (points)\n",
    "n, bins, patches = plt.hist(wines_subset[\"points\"].values,10,density=1,facecolor='green',alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0ASsfjQKCro"
   },
   "outputs": [],
   "source": [
    "y = wines_subset[\"points\"]\n",
    "y = y.where(y>90,other=0).where(y<=90,other=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlkycIzvKID2"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = tts(X,y,test_size=0.25,random_state=1693)\n",
    "#scale_X = StandardScaler()\n",
    "#X_train = scale_X.fit_transform(X_train)\n",
    "#X_test = scale_X.transform(X_test)\n",
    "classifier = LogisticRegression(random_state=1693,solver='lbfgs')\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3FQUwCtKLdV"
   },
   "outputs": [],
   "source": [
    "spc = ['Bad','Good']\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "pd.DataFrame(cm, columns=spc, index=spc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "work_p132",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
